
# Author: Christoph Lassner.
#
# This is an automatically generated file!
#
r"""
Presents a convenience wrapper for the pyfertilized module.

This wrapper offers meaningful method signatures, docstrings, and most
important, the `Soil` class, that offers the possibility to specify once
the datatypes and then generate objects that can work with the according
data.

This file is automatically generated!
"""
from fertilized.TypeTranslations import _dtype_str_translation
import os
import fertilized.pyfertilized_vec as _pyfertilized_vec

def import_by_name(name):
    mod = __import__(name)
    components = name.split('.')
    for comp in components[1:]:
        mod = getattr(mod, comp)
    return mod

_part_id = 0
_pyfertilized = []
while True:
    try:
        _pyfertilized.append(import_by_name('fertilized.pyfertilized_%d' % (_part_id)))
    except Exception as ex:
        break
    _part_id += 1
import fertilized.pyfertilized_mf as _pyfertilized_mf

def _enum(*sequential, **named):
    enums = dict(zip(sequential, range(len(sequential))), **named)
    reverse = dict((value, key) for key, value in list(enums.items()))
    enums['reverse_mapping'] = reverse
    enums['keys'] = list(range(len(sequential)))
    return type('Enum', (), enums)

__all__ = ["Soil", "Result_Types", "_pyfertilized", "_pyfertilized_mf"]

Result_Types = _enum('probabilities',
                     'hough_map',
                     'regression')

_res_type_str_translation = { Result_Types.probabilities:["fv","fv"],
                              Result_Types.hough_map:["hp", "vhp"],
                              Result_Types.regression:["rp","vprpf"]}

# Default initializations.
_DEFAULT_ENTROPY_VEC_2 = ['induced', 'induced']
_DEFAULT_ENTROPY_P1_2 = [2., 1.1]

class Soil:
  r"""
  Convenience factory class for creating forest objects of specified types.

  You can create a `Soil` once with a given set of types that you want to
  work with. All following objects constructed by the soil objects work
  with according types, so that you don't have to worry about this detail.

  All these objects can be found in the `pyfertilized`-module, but they
  have unhandy, long names and it is necessary to repeatedly find the
  correct object with the proper name.

  Take into account, that not all objects can be created by a `Soil` of a
  specific type! Calling the respective functions throws an exception.

  The datatype strings are translated into an internal string representation,
  so they can be specified quite freely, e.g. specyfing `f` or `float` is
  both understood as `float`. Take into account, that these datatypes are
  interpreted like the C++ datatypes, i.e. `float` is (usually) a 32-bit
  floating point number, and `double` is (usually) the 64-bit counterpart
  as opposed to python that doesn't know 32-bit floats and calls 64-bit
  floating point numbers `float`.

  There is the enum `Result_Types` available in this package, that provides
  access to the different result types.

  Example usage:

  >>> soil = Soil(result_type=Result_Types.probabilities)
  >>> leaf_manager = soil.ClassificationLeafManager(2)
  <fertilized.pyfertilized.ClassificationLeafManager_f_uint at 0x7c849a8>

  A leaf manager working with the proper types (in this case
  `float` and `unsigned int`) has been created.
  """
  def __init__(self, input_dtype_str='float',
                     feature_dtype_str='float',
                     annotation_dtype_str='uint',
                     result_type=Result_Types.probabilities):
    if input_dtype_str in _dtype_str_translation:
      self._inp_str = _dtype_str_translation[input_dtype_str]
    else:
      raise Exception("Unknown input dtype string! Knwon strings are: " +\
                      ', '.join(list(_dtype_str_translation.keys())))

    if feature_dtype_str in _dtype_str_translation:
      self._feat_str = _dtype_str_translation[feature_dtype_str]
    else:
      raise Exception("Unknown feature dtype string! Knwon strings are: " +\
                      ', '.join(list(_dtype_str_translation.keys())))
    if annotation_dtype_str in _dtype_str_translation:
      self._ann_str = _dtype_str_translation[annotation_dtype_str]
    else:
      raise Exception("Unknown annotation dtype string! Knwon strings are: " +\
                      ', '.join(list(_dtype_str_translation.keys())))

    self._res_type = result_type
    if self._res_type == Result_Types.regression:
      self._tres = _res_type_str_translation[result_type][0] + self._inp_str
      self._fres = _res_type_str_translation[result_type][1] + self._inp_str
    elif self._res_type == Result_Types.probabilities or \
         self._res_type == Result_Types.hough_map:
      self._tres = _res_type_str_translation[result_type][0]
      self._fres = _res_type_str_translation[result_type][1]
    else:
      raise Exception("Unknown result type!")

  def DNNFeatureExtractor(self,
        
        net_layout_file,
        net_weights_file,
        net_outlayer,
        use_cpu=0,
        device_id=0,
        mean_file=""
           ):
    r"""Class information:
    ==================
    
    Extracts DNN features using a pretrained caffe network.
    
    To obtain reproducible results, you have to remove the dropout layers
    from the network specification file (this has been done for the default
    AlexNet). During extraction, always the full batch size is used. This
    means, that if you repeatedly only extract features from one image with
    the extract method, most of the batch will be unused. You should observe
    large speed gains by reducing the batch size in the model specification
    file to a batch size of one in that case.
    
    The mean image must be subtracted from any image before
    using the feature extractor. This can be done within the `extract` method,
    or, if you want to use many samples from an image, you can do that before.
    The default mean image is the one of the ImageNet dataset. The mean image
    format is a text file with a very simple layout:
    
    
    - the first line consists of the number of rows,
    - the second line consists of the columns,
    - the third line consists of the number of channels,
    - the fourth line contains all pixel values, in OpenCV memory layout
    (rows, columns, channels, where channels are contiguous).
    
    -----

    Available in:
    - C++
    - Python
    - Matlab
    
    
    -----

    Constructor:
    ============
    
    Standard constructor.
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    net_layout_file : string
      The protobuf file describing the network layout.
    
    
    net_weights_file : string
      Filename of the pretrained network weights file.
    
    
    net_outlayer : string
      The name of the blob and layer from which to read.
    
    
    use_cpu : bool
      Whether to only use the CPU or use the GPU. Default: false.
    
    
    device_id : int>=0
      The CUDA device id. Only relevant, if `use_cpu` is false. Default: 0.
    
    
    mean_file : string
      The filename of the mean image file to use. For a file
      format description, see the documentation of this class. Default: "".
      If this is an empty string, do not use a mean.
    r"""
    attrname = 'DNNFeatureExtractor' % ()
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        net_layout_file,
        net_weights_file,
        net_outlayer,
        use_cpu,
        device_id,
        mean_file
          )
    return obj

  def Forest(self,
        
        max_tree_depth,
        min_samples_at_leaf,
        min_samples_at_node,
        n_trees,
        deciders,
        leaf_managers,
        training
           ):
    r"""Class information:
    ==================
    
    Standard forest class of the library.
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - int; int; uint; std::vector<float>; std::vector<float>
    - float; float; uint; std::vector<float>; std::vector<float>
    - double; double; uint; std::vector<float>; std::vector<float>
    - uint8_t; uint8_t; uint; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; int16_t; std::pair<float, std::shared_ptr<std::vector<int16_t>>>; std::vector<std::pair<float, std::shared_ptr<std::vector<int16_t>>>>
    - float; float; float; std::pair<std::shared_ptr<std::vector<float>>,std::shared_ptr<std::vector<float>>>; std::vector<std::pair<std::pair<std::shared_ptr<std::vector<float>>,std::shared_ptr<std::vector<float>>>,float>>
    - double; double; double; std::pair<std::shared_ptr<std::vector<double>>,std::shared_ptr<std::vector<double>>>; std::vector<std::pair<std::pair<std::shared_ptr<std::vector<double>>,std::shared_ptr<std::vector<double>>>,float>>
    
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    max_tree_depth : uint > 0
      The maximum tree depth, including leafs (up to including).
    
    min_samples_at_leaf : uint > 0
      The minimum number of samples at a leaf (from including).
    
    min_samples_at_node : uint>=2*min_samples_at_leaf
      The minimum number of samples at a node (from including).
    
    n_trees : uint>1
      The number of trees.
    
    deciders : vector(shared(IDecider))
      The deciders for each tree.
    
    leaf_managers : vector(shared(ILeafManager))
      The leaf managers for each tree.
    
    training : ITraining
      The training to use.
    r"""
    attrname = 'Forest_%s_%s_%s_%s_%s' % (self._inp_str, self._feat_str, self._ann_str, self._tres, self._fres)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        max_tree_depth,
        min_samples_at_leaf,
        min_samples_at_node,
        n_trees,
        deciders,
        leaf_managers,
        training
          )
    return obj

  def ForestFromTrees(self,
        
        trees,
        training
           ):
    r"""Class information:
    ==================
    
    Standard forest class of the library.
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - int; int; uint; std::vector<float>; std::vector<float>
    - float; float; uint; std::vector<float>; std::vector<float>
    - double; double; uint; std::vector<float>; std::vector<float>
    - uint8_t; uint8_t; uint; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; int16_t; std::pair<float, std::shared_ptr<std::vector<int16_t>>>; std::vector<std::pair<float, std::shared_ptr<std::vector<int16_t>>>>
    - float; float; float; std::pair<std::shared_ptr<std::vector<float>>,std::shared_ptr<std::vector<float>>>; std::vector<std::pair<std::pair<std::shared_ptr<std::vector<float>>,std::shared_ptr<std::vector<float>>>,float>>
    - double; double; double; std::pair<std::shared_ptr<std::vector<double>>,std::shared_ptr<std::vector<double>>>; std::vector<std::pair<std::pair<std::shared_ptr<std::vector<double>>,std::shared_ptr<std::vector<double>>>,float>>
    
    
    -----

    Constructor:
    ============
    
    Combines UNTRAINED trees to a forest.
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Exported name: ForestFromTrees
    
    -----

    
    Parameters
    ==========
    
    trees : vector(shared(Tree))
      The untrained trees.
    
    training : ITraining
      The training to use.
    r"""
    attrname = 'Forest_%s_%s_%s_%s_%s' % (self._inp_str, self._feat_str, self._ann_str, self._tres, self._fres)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        trees,
        training
          )
    return obj

  def CombineTrees(self,
        
        trees
           ):
    r"""Class information:
    ==================
    
    Standard forest class of the library.
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - int; int; uint; std::vector<float>; std::vector<float>
    - float; float; uint; std::vector<float>; std::vector<float>
    - double; double; uint; std::vector<float>; std::vector<float>
    - uint8_t; uint8_t; uint; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; int16_t; std::pair<float, std::shared_ptr<std::vector<int16_t>>>; std::vector<std::pair<float, std::shared_ptr<std::vector<int16_t>>>>
    - float; float; float; std::pair<std::shared_ptr<std::vector<float>>,std::shared_ptr<std::vector<float>>>; std::vector<std::pair<std::pair<std::shared_ptr<std::vector<float>>,std::shared_ptr<std::vector<float>>>,float>>
    - double; double; double; std::pair<std::shared_ptr<std::vector<double>>,std::shared_ptr<std::vector<double>>>; std::vector<std::pair<std::pair<std::shared_ptr<std::vector<double>>,std::shared_ptr<std::vector<double>>>,float>>
    
    
    -----

    Constructor:
    ============
    
    Combines TRAINED trees to a forest. !! Training is not possible any more !!
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Exported name: CombineTrees
    
    -----

    
    Parameters
    ==========
    
    trees : vector(shared(Tree))
      The trained trees to combine.
    r"""
    attrname = 'Forest_%s_%s_%s_%s_%s' % (self._inp_str, self._feat_str, self._ann_str, self._tres, self._fres)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        trees
          )
    return obj

  def ForestFromFile(self,
        
        filename
           ):
    r"""Class information:
    ==================
    
    Standard forest class of the library.
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - int; int; uint; std::vector<float>; std::vector<float>
    - float; float; uint; std::vector<float>; std::vector<float>
    - double; double; uint; std::vector<float>; std::vector<float>
    - uint8_t; uint8_t; uint; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; int16_t; std::pair<float, std::shared_ptr<std::vector<int16_t>>>; std::vector<std::pair<float, std::shared_ptr<std::vector<int16_t>>>>
    - float; float; float; std::pair<std::shared_ptr<std::vector<float>>,std::shared_ptr<std::vector<float>>>; std::vector<std::pair<std::pair<std::shared_ptr<std::vector<float>>,std::shared_ptr<std::vector<float>>>,float>>
    - double; double; double; std::pair<std::shared_ptr<std::vector<double>>,std::shared_ptr<std::vector<double>>>; std::vector<std::pair<std::pair<std::shared_ptr<std::vector<double>>,std::shared_ptr<std::vector<double>>>,float>>
    
    
    -----

    Constructor:
    ============
    
    Deserializing constructor to load a forest from a file.
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Exported name: ForestFromFile
    
    -----

    
    Parameters
    ==========
    
    filename : string
      The file to load the forest from.
    r"""
    attrname = 'Forest_%s_%s_%s_%s_%s' % (self._inp_str, self._feat_str, self._ann_str, self._tres, self._fres)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        filename
          )
    return obj

  def ObjectTemplate(self,
        
        example_param
           ):
    r"""Class information:
    ==================
    
    Object template.
    
    After having described the object, add a section like the following
    to specify in which interfaces the object should be available, and, if it
    is templated, which instantiations of the object. The instantiations are
    ;-separated lists of the C++ types to use.
    
    To start and end this section, use exactly -----. End the lists with a dot
    and add an empty line after the last list. This is not due to our parser,
    but due to doxygen. It is required to get a meaningful rendering for the
    documentation.
    
    Use exactly the library template names `input_dtype`, `feature_dtype`,
    `annotation_dtype`, `leaf_return_dtype`, `forest_dtype` for your
    objects as necessary (you may omit unnecessary ones). If your class is
    templated differently, only one possible
    template instantiation can be used for the interfaces. In that case, you
    have to specify this with a parser list "Soil type always:". You can find
    an example for this in impurities/shannonentropy.h.
    
    The specification of the "Serialization generation:" is important if you
    want to serialize your object and remain compatible to older versions
    of the library. Specify the number as the version number of the library
    in hundreds format (e.g., 1.00 as 100) plus one
    (e.g., if the current library version is 1.01, use 102). Your self-
    compiled library version with the additional object will be backwards
    compatible with all lower library versions. Increase the library version in
    the file 'global.h' to the same value!
    
    IMPORTANT: you HAVE to adjust the `Serializaton generation:` version number
    and the library version in 'global.h' to serialize your object and
    maintain backwards compatibility!
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - int; int; uint; std::vector<float>; std::vector<float>
    - float; float; uint; std::vector<float>; std::vector<float>
    
    Serialization generation: 100
    
    -----

    Constructor:
    ============
    
    For every method, including the constructor, you can specify a
    list of interfaces in which the method should be exported. Add the
    description of the parameters after the specification (this is again
    just to get nice doxygen results). Parameter conversion code for method
    arguments is generated automatically for
    
    - all plain C++ types,
    - vectors of these types,
    - 'Array's,
    - vectors of 'Array's,
    - library objects,
    - vectors of library objects.
    
    Return types may be
    - all plain C++ types,
    - vectors of these types,
    - 'Array's,
    - library objects (not available for Matlab!),
    - vectors of library objects (not available for Matlab!).
    
    Remember to run `scons --generate-interfaces` to update all language
    interfaces after a change to your class specification. This also requires
    compilation.
    
    -----

    Available in:
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    example_param : uint > 0
      An example parameter to illustrate the documentation.
    r"""
    attrname = 'ObjectTemplate_%s_%s_%s_%s_%s' % (self._inp_str, self._feat_str, self._ann_str, self._tres, self._fres)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        example_param
          )
    return obj

  def Tree(self,
        
        max_depth,
        min_samples_at_leaf,
        min_samples_at_node,
        decider,
        leaf_manager
           ):
    r"""Class information:
    ==================
    
    The main tree class for the fertilized framework.
    
    This class is the core element of the framework. It can be used as a
    standalone tree or to form a forest. It is highly customizable by
    providing the IClassifierManager and ILeafManager.
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - int; int; uint; std::vector<float>; std::vector<float>
    - float; float; uint; std::vector<float>; std::vector<float>
    - double; double; uint; std::vector<float>; std::vector<float>
    - uint8_t; uint8_t; uint; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; uint; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; int16_t; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; int16_t; std::pair<float, std::shared_ptr<std::vector<int16_t>>>; std::vector<std::pair<float, std::shared_ptr<std::vector<int16_t>>>>
    - float; float; float; std::pair<std::shared_ptr<std::vector<float>>,std::shared_ptr<std::vector<float>>>; std::vector<std::pair<std::pair<std::shared_ptr<std::vector<float>>,std::shared_ptr<std::vector<float>>>,float>>
    - double; double; double; std::pair<std::shared_ptr<std::vector<double>>,std::shared_ptr<std::vector<double>>>; std::vector<std::pair<std::pair<std::shared_ptr<std::vector<double>>,std::shared_ptr<std::vector<double>>>,float>>
    
    
    -----

    Constructor:
    ============
    
    The standard constructor for the fertilized trees.
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    max_depth : uint > 0
      The maximum tree depth, including leafs (up to including).
    
    min_samples_at_leaf : uint > 0
      The minimum number of samples at a leaf (from including).
    
    min_samples_at_node : uint>=2*min_samples_at_leaf
      The minimum number of samples at a node (from including).
    
    decider : IDecider
      The decider that stores, optimizes and applies the decision rules
      for each inner tree node.
    
    leaf_manager : The leaf manager generates, stores and handles
      the return values of the leaf nodes.
    r"""
    attrname = 'Tree_%s_%s_%s_%s_%s' % (self._inp_str, self._feat_str, self._ann_str, self._tres, self._fres)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        max_depth,
        min_samples_at_leaf,
        min_samples_at_node,
        decider,
        leaf_manager
          )
    return obj

  def TreeFromFile(self,
        
        filename
           ):
    r"""Class information:
    ==================
    
    The main tree class for the fertilized framework.
    
    This class is the core element of the framework. It can be used as a
    standalone tree or to form a forest. It is highly customizable by
    providing the IClassifierManager and ILeafManager.
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - int; int; uint; std::vector<float>; std::vector<float>
    - float; float; uint; std::vector<float>; std::vector<float>
    - double; double; uint; std::vector<float>; std::vector<float>
    - uint8_t; uint8_t; uint; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; uint; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; int16_t; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; int16_t; std::pair<float, std::shared_ptr<std::vector<int16_t>>>; std::vector<std::pair<float, std::shared_ptr<std::vector<int16_t>>>>
    - float; float; float; std::pair<std::shared_ptr<std::vector<float>>,std::shared_ptr<std::vector<float>>>; std::vector<std::pair<std::pair<std::shared_ptr<std::vector<float>>,std::shared_ptr<std::vector<float>>>,float>>
    - double; double; double; std::pair<std::shared_ptr<std::vector<double>>,std::shared_ptr<std::vector<double>>>; std::vector<std::pair<std::pair<std::shared_ptr<std::vector<double>>,std::shared_ptr<std::vector<double>>>,float>>
    
    
    -----

    Constructor:
    ============
    
    Deserialization constructor for the fertilized trees.
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Exported name: TreeFromFile
    
    -----

    
    Parameters
    ==========
    
    filename : string
      The filename to deserialize the tree from.
    r"""
    attrname = 'Tree_%s_%s_%s_%s_%s' % (self._inp_str, self._feat_str, self._ann_str, self._tres, self._fres)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        filename
          )
    return obj

  def AdaBoost(self,
        
           ):
    r"""Class information:
    ==================
    
    AdaBoost.M2 boosting algorithm implementation
    
    Implements the original AdaBoost algorithm proposed by Freund and Schapire
    
    See "A decision-theoretic generalization of on-line learning and an
    application to boosting". Journal of Computer and System Sciences 55. 1997
    
    To support multi-class classification, the AdaBoost.M2 algorithm is used.
    
    Output when using BoostingLeafManager is
    estimator_probability*std::log(1.f/beta).
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - int; int; uint; std::vector<float>; std::vector<float>
    - float; float; uint; std::vector<float>; std::vector<float>
    - double; double; uint; std::vector<float>; std::vector<float>
    - uint8_t; uint8_t; uint; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; uint; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; int16_t; std::vector<float>; std::vector<float>
    
    Serialization generation: 101
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    r"""
    attrname = 'AdaBoost_%s_%s_%s_%s_%s' % (self._inp_str, self._feat_str, self._ann_str, self._tres, self._fres)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
          )
    return obj

  def AlignedSurfaceCalculator(self,
        
           ):
    r"""Class information:
    ==================
    
    Forwards the data as features.
    
    Does not require any parameters.
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - int; uint
    - uint8_t; uint
    - float; uint
    - float; float
    - double; uint
    - double; double
    
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    r"""
    attrname = 'AlignedSurfaceCalculator_%s_%s' % (self._inp_str, self._ann_str)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
          )
    return obj

  def AlternatingThresholdOptimizer(self,
        
        opt1,
        opt2,
        random_seed=1
           ):
    r"""Class information:
    ==================
    
    Uses two other threshold optimizers and randomly selects one of them at each split.
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - float; float; float
    - double; double; double
    - int; int; uint
    - int; float; uint
    - float; int; uint
    - uint8_t; int; uint
    - uint8_t; uint8_t; uint
    - uint8_t; float; uint
    - uint8_t; int16_t; uint
    - float; float; uint
    - double; double; uint
    - uint8_t; int16_t; int16_t
    
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    opt1 : shared(IThresholdOptimizer)
      The first threshold optimizer to alternate in between.
    
    opt2 : shared(IThresholdOptimizer)
      The second threshold optimizer to alternate in between.
    
    random_seed : uint>0
      The random seed for the RNG. Default: 1.
    r"""
    attrname = 'AlternatingThresholdOptimizer_%s_%s_%s' % (self._inp_str, self._feat_str, self._ann_str)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        opt1,
        opt2,
        random_seed
          )
    return obj

  def BoostedTraining(self,
        
        boosting_strategy
           ):
    r"""Class information:
    ==================
    
    Implements a boosted training that uses a boosting implementation defined by an IBoostingStrategy
    
    Trains all trees using a given boosting algorithm implementation
    Use a BoostingLeafManager to let the boosting strategies decide their weight functions
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - int; int; uint; std::vector<float>; std::vector<float>
    - float; float; uint; std::vector<float>; std::vector<float>
    - double; double; uint; std::vector<float>; std::vector<float>
    - uint8_t; uint8_t; uint; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; uint; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; int16_t; std::vector<float>; std::vector<float>
    
    Serialization generation: 101
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    bagging_strategy : IBagginStrategy
      The bagging strategy to use to distribute samples amongst trees.
    r"""
    attrname = 'BoostedTraining_%s_%s_%s_%s_%s' % (self._inp_str, self._feat_str, self._ann_str, self._tres, self._fres)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        boosting_strategy
          )
    return obj

  def ClassicTraining(self,
        
        bagging_strategy
           ):
    r"""Class information:
    ==================
    
    Implements the vanilla decision forest training.
    
    Trains all trees independent of each other as allowed by the
    IExecutionStrategy, possibly exploiting parallelism, etc.
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - int; int; uint; std::vector<float>; std::vector<float>
    - float; float; uint; std::vector<float>; std::vector<float>
    - double; double; uint; std::vector<float>; std::vector<float>
    - uint8_t; uint8_t; uint; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; uint; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; int16_t; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; int16_t; std::pair<float, std::shared_ptr<std::vector<int16_t>>>; std::vector<std::pair<float, std::shared_ptr<std::vector<int16_t>>>>
    - float; float; float; std::pair<std::shared_ptr<std::vector<float>>,std::shared_ptr<std::vector<float>>>; std::vector<std::pair<std::pair<std::shared_ptr<std::vector<float>>,std::shared_ptr<std::vector<float>>>,float>>
    - double; double; double; std::pair<std::shared_ptr<std::vector<double>>,std::shared_ptr<std::vector<double>>>; std::vector<std::pair<std::pair<std::shared_ptr<std::vector<double>>,std::shared_ptr<std::vector<double>>>,float>>
    
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    bagging_strategy : IBagginStrategy
      The bagging strategy to use to distribute samples amongst trees.
    r"""
    attrname = 'ClassicTraining_%s_%s_%s_%s_%s' % (self._inp_str, self._feat_str, self._ann_str, self._tres, self._fres)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        bagging_strategy
          )
    return obj

  def ClassificationError(self,
        
           ):
    r"""Class information:
    ==================
    
    Computes the classification error as 1-\max(p_i).
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - float
    - uint
    
    Soil type always:
    
    - float
    
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    r"""
    attrname = 'ClassificationError_%s' % ('f')
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
          )
    return obj

  def ClassificationLeafManager(self,
        
        n_classes
           ):
    r"""Class information:
    ==================
    
    Stores the probability distributions for n_classes at a leaf.
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - int; uint
    - float; uint
    - double; uint
    - uint8_t; uint
    - uint8_t; int16_t
    
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    n_classes : uint>1
      The number of classes.
    r"""
    attrname = 'ClassificationLeafManager_%s_%s' % (self._inp_str, self._ann_str)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        n_classes
          )
    return obj

  def ClassificationThresholdOptimizer(self,
        
        use_fast_search_approximation,
        n_classes,
        gain_calculator,
        gain_threshold=1E-7,
        annotation_step=1
           ):
    r"""Class information:
    ==================
    
    Optimizes one threshold very efficiently.
    
    Supports only classification annotations (unsigned int) with annotation
    values ranging in [0; n_classes - 1]. Searches the perfect threshold to
    split the data.
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - int; int; uint
    - int; float; uint
    - float; int; uint
    - uint8_t; int; uint
    - uint8_t; uint8_t; uint
    - uint8_t; float; uint
    - uint8_t; int16_t; uint
    - float; float; uint
    - double; double; uint
    - uint8_t; int16_t; int16_t
    
    
    -----

    Constructor:
    ============
    
    Standard constructor.
    
    use_fast_search_approximation is an interesting option to speed up the
    optimization process. In general, the elements are considered in sorted
    feature order. If use_fast_search_approximation is set to true, the
    gain is only calculated at positions, where the currently considered
    element is from a different class than the last one AND if the
    feature value changed.
    
    This is a true approximation (i.e. the optimal gain can be at a
    position where the current element is from the same class than the
    last), but this hardly ever occurs for the usual gain calculation
    functions.
    
    A necessary, but not sufficient criterion for the approximation to
    be equal to the optimal value is the following:
    Assuming the (weighted) histogram values at position :math:`k` are
    :math:`k_{li}` for the left hand-side histogram and :math:`k_{ri}` for the
    right hand-side histogram, :math:`i\in[0,n\_classes-1]`. Then the gain
    function :math:`g(.)` must have the property
    
    .. math::
      \forall j\forall k_{li},k_{ri}: g(\{k_{li}\},\{k_{ri}\})<
    g(\{k_{li}\}_{i\backslash j}\cup\{k_{lj}+1\},
    \{k_{ri}\}_{i\backslash j}\cup\{k_{rj}-1\}) \vee
    g(\{k_{li}\}_{i\backslash j}\cup\{k_{lj}-1\},
    \{k_{ri}\}_{i\backslash j}\cup\{k_{rj}+1\})
    .
    
    This does not hold in general, but for the standard information gain
    based measures, cases where it doesn't hold occur very rarely and even
    if so, the found positions aren't a lot worse than the theoretical
    optimum.
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    use_fast_search_approximation : bool
      Whether to use the approximation described above or not.
    
    n_classes : size_t >1
      The number of classes. All annotations must be in [0, ..., n_classes[.
    
    gain_calculator : IGainCalculator
      The gain calculator to estimate the gain at each split.
    
    gain_threshold : float>=0f
      The minimum gain that must be reached to continue splitting. Default: 1E-7f.
    
    annotation_step : size_t>0
      The memory step size for the annotation data. Default: 1.
    r"""
    attrname = 'ClassificationThresholdOptimizer_%s_%s_%s' % (self._inp_str, self._feat_str, self._ann_str)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        use_fast_search_approximation,
        n_classes,
        gain_calculator,
        gain_threshold,
        annotation_step
          )
    return obj

  def ConstantRegressionCalculator(self,
        
           ):
    r"""Class information:
    ==================
    
    Calculator for constant regression.
    
    This regression calculator uses a constant value to predict the output value.
    Therefore, it provides a constant prediction and a constant prediction covariance matrix.
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - float
    - double
    
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    r"""
    attrname = 'ConstantRegressionCalculator_%s' % (self._inp_str)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
          )
    return obj

  def DifferenceSurfaceCalculator(self,
        
           ):
    r"""Class information:
    ==================
    
    Calculates a feature as the difference between two data dimensions
    of inputs.
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - int; int; uint
    - uint8_t; int16_t; uint
    - float; float; uint
    - float; float; float
    - double; double; uint
    - double; double; double
    
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    r"""
    attrname = 'DifferenceSurfaceCalculator_%s_%s_%s' % (self._inp_str, self._feat_str, self._ann_str)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
          )
    return obj

  def DirectPatchDifferenceSurfCalculator(self,
        
        psx,
        psy,
        psz,
        luc
           ):
    r"""Class information:
    ==================
    
    Calculates a feature as the difference between two data dimensions
    of inputs.
    
    In contrast to the DifferenceSurfaceCalculator, works with patches
    in images directly. It only works together with a SubsamplingDataProvider
    with a NoCopyPatchSampleManager, because they provide the images
    in the correct format.
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - uint8_t; int16_t; uint
    - uint8_t; int16_t; int16_t
    
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    psx : size_t>0
      Horizontal patch size.
    
    psy : size_t>0
      Vertical patch size.
    
    psz : size_t>0
      Patch depth.
    
    luc : bool
      Whether the Left Upper Corner of a patch is used when specifying
      positions or its center.
    r"""
    attrname = 'DirectPatchDifferenceSurfCalculator_%s_%s_%s' % (self._inp_str, self._feat_str, self._ann_str)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        psx,
        psy,
        psz,
        luc
          )
    return obj

  def EntropyGain(self,
        
        entropy_function
           ):
    r"""Class information:
    ==================
    
    Calculates the gain as difference of current entropy and the
    weighted sum of subgroup entropies.
    
    Works correctly up to a total sum of elements of
    min(numeric_limits<float>::max(), numeric_limits<input_dtype>::max())
    and the limitations of the selected entropy function.
    Speed optimized function that does no checks in release mode!
    
    Parameters
    ==========
    
    input_dtype : The datatype for counting class members. This might
      be a float if sample weights are used.
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - float
    - uint
    
    Soil type always:
    
    - float
    
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    
    entropy_function : shared(IEntropyFunction<float>)
      The entropy to use for gain calculation.
    r"""
    attrname = 'EntropyGain_%s' % ('f')
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        entropy_function
          )
    return obj

  def EqualDistBagging(self,
        
           ):
    r"""Class information:
    ==================
    
    Equal distribution bagging.
    
    The samples are distributed equally amongst the trees. Each sample belongs
    to exactly one tree. Note that this behaviour destroys the max-margin
    property of decision forests.
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - int; int; uint; std::vector<float>; std::vector<float>
    - float; float; uint; std::vector<float>; std::vector<float>
    - double; double; uint; std::vector<float>; std::vector<float>
    - uint8_t; uint8_t; uint; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; uint; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; int16_t; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; int16_t; std::pair<float, std::shared_ptr<std::vector<int16_t>>>; std::vector<std::pair<float, std::shared_ptr<std::vector<int16_t>>>>
    - float; float; float; std::pair<std::shared_ptr<std::vector<float>>,std::shared_ptr<std::vector<float>>>; std::vector<std::pair<std::pair<std::shared_ptr<std::vector<float>>,std::shared_ptr<std::vector<float>>>,float>>
    - double; double; double; std::pair<std::shared_ptr<std::vector<double>>,std::shared_ptr<std::vector<double>>>; std::vector<std::pair<std::pair<std::shared_ptr<std::vector<double>>,std::shared_ptr<std::vector<double>>>,float>>
    
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    r"""
    attrname = 'EqualDistBagging_%s_%s_%s_%s_%s' % (self._inp_str, self._feat_str, self._ann_str, self._tres, self._fres)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
          )
    return obj

  def HoughLeafManager(self,
        
        n_classes=2,
        annot_dim=2
           ):
    r"""Class information:
    ==================
    
    Stores the offset vectors for positive samples and their
    probabilities in the leafs.
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - uint8_t; int16_t
    
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    n_classes : uint>1
      The number of classes. Currently only 2 are supported. Default: 2.
    
    annot_dim : size_t>0
      The number of offset dimensions. Default: 2.
    r"""
    attrname = 'HoughLeafManager_%s_%s' % (self._inp_str, self._ann_str)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        n_classes,
        annot_dim
          )
    return obj

  def InducedEntropy(self,
        
        p
           ):
    r"""Class information:
    ==================
    
    Computes the induced p entropy.
    
    Works correctly up to a total sum of elements of
    numeric_limits<input_dtype>::max().
    
    This is the induced p-metric of the vector of :math:`n` class probabilities
    and the point of maximum unorder (the vector with all entries
    :math:`\frac{1}{n}`) in the n-dimensional space without applying the root.
    It is equal to the Gini-measure for :math:`p=2`.
    
    The definition for :math:`c` classes:
    
    .. math::
      \sum_{i=1}^{c} \left\Vert p_i - 0.5\right\Vert ^p
    .
    
    The differential entropy for a normal distribution with covariance
    matrix :math:`\Sigma` in :math:`n` dimensions is defined as:
    
    .. math::
      \frac{1}{\sqrt{p^n}}\cdot\left(\sqrt{2\pi}^n\cdot\sqrt{\left|\Sigma\right|}\right)^{-(p-1)}
    
    
    In the differential normal case, the most useful values for :math:`p` are
    very close to 1 (e.g. 1.00001)! :math:`p=2` is already equivalent to the
    infinite norm!
    
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - float
    - uint
    
    Soil type always:
    
    - float
    
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    p : float>0.f
      The entropy parameter value.
    r"""
    attrname = 'InducedEntropy_%s' % ('f')
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        p
          )
    return obj

  def LinearRegressionCalculator(self,
        
        force_numerical_stability=1,
        numerical_zero_threshold=-1
           ):
    r"""Class information:
    ==================
    
    Calculator for linear regression.
    
    This regression calculator uses a linear combination of the input dimensions
    to predict the output value. Therefore it does not provide a constant prediction
    or a constant prediction covariance matrix.
    If there are multiple output values to be predicted, each output is produced
    using its own linear model.
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - float
    - double
    
    
    -----

    Constructor:
    ============
    
    Constructor for a LinearRegressionCalculator
    
    Costructs a LinearRegressionCalculator.
    If numberical stability is not forced, the linear models
    in low dimensional cases are computed using a closed form.
    This is faster but less accurate.
    Otherwise, always matrix decomposition is used which provides
    more accurate and stable solutions.
    In order to prevent numerical issues, a threshold can be specified
    to denote the smallest number that is distinct to zero.
    Using the default value -1, this threshold is determined automatically
    based on the data samples.
    
    Parameters
    ==========
    
    force_numerical_stability : Denotes, numerical stability is forced or not.
    
    numerical_zero_threshold : The threshold for the smallest number distinguished from zero.
      \returns A new LinearRegressionCalculator.
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    
    force_numerical_stability : bool
      Whether to enforce numerical stability or allow instable solutions. Default: true.
    
    numerical_zero_threshold : input_dtype >=0||-1
      Everything below this threshold is treated as zero. If set to -1.f,
      use the value proposed by Eigen. Default: -1.f
    r"""
    attrname = 'LinearRegressionCalculator_%s' % (self._inp_str)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        force_numerical_stability,
        numerical_zero_threshold
          )
    return obj

  def LinearSurfaceCalculator(self,
        
        n_params_per_feat_sel,
        n_comb_dims=2,
        random_seed=1
           ):
    r"""Class information:
    ==================
    
    Calculates a feature as linear combination of inputs.
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - int; uint
    - uint8_t; uint
    - float; uint
    - float; float
    - double; double
    - double; uint
    
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    n_params_per_feat_sel : size_t>0
      The number of linear configurations to evaluate per feature selection.
    
    n_comb_dims : size_t>0
      The dimensionality of the linear surface. Default: 2.
    
    random_seed : uint>0
      Seed for the RNG. Default: 1.
    r"""
    attrname = 'LinearSurfaceCalculator_%s_%s' % (self._inp_str, self._ann_str)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        n_params_per_feat_sel,
        n_comb_dims,
        random_seed
          )
    return obj

  def LocalExecutionStrategy(self,
        
        num_threads=1
           ):
    r"""Class information:
    ==================
    
    Executes the training on the local machine.
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - int; int; uint; std::vector<float>; std::vector<float>
    - float; float; uint; std::vector<float>; std::vector<float>
    - double; double; uint; std::vector<float>; std::vector<float>
    - uint8_t; uint8_t; uint; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; uint; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; int16_t; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; int16_t; std::pair<float, std::shared_ptr<std::vector<int16_t>>>; std::vector<std::pair<float, std::shared_ptr<std::vector<int16_t>>>>
    - float; float; float; std::pair<std::shared_ptr<std::vector<float>>,std::shared_ptr<std::vector<float>>>; std::vector<std::pair<std::pair<std::shared_ptr<std::vector<float>>,std::shared_ptr<std::vector<float>>>,float>>
    - double; double; double; std::pair<std::shared_ptr<std::vector<double>>,std::shared_ptr<std::vector<double>>>; std::vector<std::pair<std::pair<std::shared_ptr<std::vector<double>>,std::shared_ptr<std::vector<double>>>,float>>
    
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    num_threads : int>0
      The number of threads to use for parallelism on forest training level.
      Note that this multiplies with the parallelism applied for training
      steps, such as for IDecider optimization! Default: 1.
    r"""
    attrname = 'LocalExecutionStrategy_%s_%s_%s_%s_%s' % (self._inp_str, self._feat_str, self._ann_str, self._tres, self._fres)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        num_threads
          )
    return obj

  def NoBagging(self,
        
           ):
    r"""Class information:
    ==================
    
    As the name suggests, performs no bagging and uses all samples for all trees.
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - int; int; uint; std::vector<float>; std::vector<float>
    - float; float; uint; std::vector<float>; std::vector<float>
    - double; double; uint; std::vector<float>; std::vector<float>
    - uint8_t; uint8_t; uint; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; uint; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; int16_t; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; int16_t; std::pair<float, std::shared_ptr<std::vector<int16_t>>>; std::vector<std::pair<float, std::shared_ptr<std::vector<int16_t>>>>
    - float; float; float; std::pair<std::shared_ptr<std::vector<float>>,std::shared_ptr<std::vector<float>>>; std::vector<std::pair<std::pair<std::shared_ptr<std::vector<float>>,std::shared_ptr<std::vector<float>>>,float>>
    - double; double; double; std::pair<std::shared_ptr<std::vector<double>>,std::shared_ptr<std::vector<double>>>; std::vector<std::pair<std::pair<std::shared_ptr<std::vector<double>>,std::shared_ptr<std::vector<double>>>,float>>
    
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    r"""
    attrname = 'NoBagging_%s_%s_%s_%s_%s' % (self._inp_str, self._feat_str, self._ann_str, self._tres, self._fres)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
          )
    return obj

  def PatchSampleManager(self,
        
        images,
        patch_descs,
        n_positives,
        patch_size_z,
        patch_size_y,
        patch_size_x,
        patches_luc=0
           ):
    r"""Class information:
    ==================
    
    Manages patch samples for the SubsamlingDataProvider.
    
    Loads patches from the images on-demand and always has only
    the maximum allowed number of patches in memory. This exception
    might only be violated at leafs.
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - uint8_t; int16_t
    - uint8_t; uint
    
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    images : vector(Array<input_dtype>, 3D, row-major contiguous)
      Images of shape (n_features, height, width).
    
    patch_descs : Array<annotation_dtype, 3D, row-major contiguous)
      2D array in row major format with
      the patch descriptions. A patch description consists of 5 values:
      image id, position x, y, offset x, y (from the object to detect,
      so that position x + offset x = object x).
    
    n_positives : size_t>0
      The first n_positive examples are interpreted as
      positives, the rest as negatives (they get an according annotation).
    
    patch_size_z : size_t>0
      Patch depth.
    
    patch_size_y : size_t>0
      Patch height.
    
    patch_size_x : size_t>0
      Patch width.
    
    patches_luc : bool
      If true, it is assumed that the patch descriptions
      contain the _L_eft _U_pper _C_orners of the patches. Otherwise, it
      it assumed they contain the center points. In the luc case, the patch
      goes from (including) position{x,y} to (excluding)
      position{x,y}+{width, height}. In the center case, the patch goes
      from (including) position{x,y}-{width//2, height//2} up to (excluding)
      position{x,y}-{(width//2-width), (height//2-height)}. Default: false.
    r"""
    attrname = 'PatchSampleManager_%s_%s' % (self._inp_str, self._ann_str)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        images,
        patch_descs,
        n_positives,
        patch_size_z,
        patch_size_y,
        patch_size_x,
        patches_luc
          )
    return obj

  def QuadraticSurfaceCalculator(self,
        
        n_params_per_feat_sel,
        min_max_vals,
        random_seed=1
           ):
    r"""Class information:
    ==================
    
    Calculates a feature as the response value of a quadratic
    surface (see CriminisiShotton 2013, p. 15). Currently only supports two
    feature dimensions.
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - int; uint
    - uint8_t; uint
    - float; uint
    - float; float
    - double; uint
    - double; double
    
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    n_params_per_feat_sel : size_t>0
      The number of surfaces to evaluate per feature selection.
    
    min_max_vals : vector<float>
      The relevant range for each feature dimension.
    
    random_seed : uint>0
      Seed for the RNG.
    r"""
    attrname = 'QuadraticSurfaceCalculator_%s_%s' % (self._inp_str, self._ann_str)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        n_params_per_feat_sel,
        min_max_vals,
        random_seed
          )
    return obj

  def RandomizedClassificationThresholdOptimizer(self,
        
        n_thresholds,
        n_classes,
        gain_calculator,
        gain_threshold=1E-7,
        annotation_step=1,
        random_seed=1
           ):
    r"""Class information:
    ==================
    
    Optimizes a threshold by selecting the best of few random values.
    
    Supports only classification annotations (unsigned int) with annotation
    values in [0, ..., n_classes[.
    The threshold optimizer draws n_thresholds random values between
    the minimum and maximum observed feature value and returns the best
    one.
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - int; int; uint
    - int; float; uint
    - float; int; uint
    - uint8_t; int; uint
    - uint8_t; uint8_t; uint
    - uint8_t; float; uint
    - uint8_t; int16_t; uint
    - float; float; uint
    - double; double; uint
    - uint8_t; int16_t; int16_t
    
    
    -----

    Constructor:
    ============
    
    Standard constructor.
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    n_thresholds : size_t>0
      The number of thresholds to test per node.
    
    n_classes : size_t>1
      The number of classes. All annotations must be within
      [0, ..., n_classes[.
    
    gain_calculator : IGainCalculator
      The gain calculator to use.
    
    gain_threshold : float >= 0f
      The minimum gain that must be reached to continue splitting. Optional.
    
    annotation_step : size_t>0
      The memory step from one annotation value to the next. Optional.
    
    random_seed : uint>0
      The random seed to initialize the RNG. Optional.
    r"""
    attrname = 'RandomizedClassificationThresholdOptimizer_%s_%s_%s' % (self._inp_str, self._feat_str, self._ann_str)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        n_thresholds,
        n_classes,
        gain_calculator,
        gain_threshold,
        annotation_step,
        random_seed
          )
    return obj

  def RegressionLeafManager(self,
        
        selection_provider,
        n_valids_to_use,
        regression_calculator,
        entropy_function,
        use_fallback_constant_regression=0,
        num_threads=1,
        summary_mode=0
           ):
    r"""Class information:
    ==================
    
    Manages the leaf nodes of regression trees.
    
    This leaf manager creates leaf nodes and stores a probabilistic regression
    model at each leaf.
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - float
    - double
    
    
    -----

    Constructor:
    ============
    
    Constructor for a RegressionLeafManager
    
    Costructs a RegressionLeafManager.
    For each leaf, a number of dimension selections used as regressors is asessed.
    The selection resulting in the regression model with the lowest entropy is used.
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    selection_provider : ISelectionProvider
      Selection provider creating random feature selections.
      It specifies, how many regressors are used.
    
    n_valids_to_use : size_t>0
      How many valid selections are asessed, until the selection process is
      stopped.
    
    regression_calculator : IRegressionCalculator
      The regression calculator that is used to generate a regression model for each leaf.
    
    entropy_function : IEntropyFunction
      The entropy function used to evaluate the regression models.
    
    use_fallback_constant_regression : bool
      When no valid dimension selections can be found and this flag is set to true,
      a ConstantRegressionCalculator (independent from regressor selections) is used instead.
      Otherwise, this case results in a runtime exception. Default: false.
    
    num_threads : int>0
      The number of threads used when evaluating different selections.
      Default: 1.
    
    summary_mode : uint<3
      Determines the meaning of the values in the 2D prediction matrix of
      a forest (the output of the convenience `predict` method of a forest).
      Case 0: Each row contains the prediction for each regressor (the first
      half of its entries) and the expected variances for each
      regressor (second half of its entries). To estimate the joint
      variance, a gaussian is fitted over the multimodal distribution
      defined by all trees.
      Case 1: Each row contains the prediction for each regressor (the first
      half of its entries) and the mean of the expected variances of
      each tree. This has no direct semantic meaning, but can give
      better results in active learning applications.
      Case 2: Each row contains the prediction for each regressor and
      the variance estimate for each regressor for each tree, e.g.,
      (r11, r12, v11, v12, r21, r22, v21, v22, ...), with `r` and `v`
      denoting regressor prediction and variance respectively, the
      first index the tree and the second index the regressor index.
      \returns A new RegressionLeafManager.
    r"""
    attrname = 'RegressionLeafManager_%s' % (self._inp_str)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        selection_provider,
        n_valids_to_use,
        regression_calculator,
        entropy_function,
        use_fallback_constant_regression,
        num_threads,
        summary_mode
          )
    return obj

  def RegressionThresholdOptimizer(self,
        
        n_thresholds,
        regression_calculator,
        entropy_function,
        gain_threshold=1E-7,
        annotation_step=1,
        random_seed=1
           ):
    r"""Class information:
    ==================
    
    Optimizes the threshold for splitting a dataset, to ensure optimal
    regression results on the splits.
    
    This threshold optimizer draws n_thresholds random values between
    the minimum and maximum observed feature value and returns the best
    one.
    Multiple annotations (and therefore multiple output regression) are allowed.
    The splits are evaluated using a provided regression calculator.
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - float; float
    - double; double
    
    
    -----

    
    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    n_thresholds : size_t>0
      Number of randomly drawn threshold values that are asessed.
    
    regression_calculator : shared(IRegressionCalculator)
      The regression calculator used to evaluate possible splits.
    
    entropy_function : shared(IEntropyFunction)
      The entropy function used on the regression results.
    
    gain_threshold : float >=0.f
      The minimum information gain a split has to achieve.
    
    annotation_step : size_t >0
      The memory layout of sample annotations.
    
    random_seed : uint >0
      The random seed.
      \returns A new RegressionThresholdOptimizer.
    r"""
    attrname = 'RegressionThresholdOptimizer_%s_%s' % (self._inp_str, self._feat_str)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        n_thresholds,
        regression_calculator,
        entropy_function,
        gain_threshold,
        annotation_step,
        random_seed
          )
    return obj

  def RenyiEntropy(self,
        
        alpha
           ):
    r"""Class information:
    ==================
    
    Computes the Renyi entropy.
    
    Works correctly up to a total sum of elements of
    numeric_limits<input_dtype>::max().
    
    This is the Renyi entropy, as introduced by Alfred Renyi
    (see http://en.wikipedia.org/wiki/R%C3%A9nyi_entropy).
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - float
    - uint
    
    Soil type always:
    
    - float
    
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    alpha : float>0.f
      The entropy parameter.
    r"""
    attrname = 'RenyiEntropy_%s' % ('f')
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        alpha
          )
    return obj

  def Samme(self,
        
        learning_rate=1
           ):
    r"""Class information:
    ==================
    
    SAMME boosting algorithm implementation
    
    Implements the SAMME boosting algorithm proposed by J. Zhu, H. Zou,
    S. Rosset and T. Hastie ("Multi-class AdaBoost", 2009).
    
    One can set the learning rate which specifies the contribution of each
    classifier.
    
    Output when using BoostingLeafManager is
    estimator_probability*estimator_weight.
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - int; int; uint; std::vector<float>; std::vector<float>
    - float; float; uint; std::vector<float>; std::vector<float>
    - double; double; uint; std::vector<float>; std::vector<float>
    - uint8_t; uint8_t; uint; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; uint; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; int16_t; std::vector<float>; std::vector<float>
    
    Serialization generation: 101
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    r"""
    attrname = 'Samme_%s_%s_%s_%s_%s' % (self._inp_str, self._feat_str, self._ann_str, self._tres, self._fres)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        learning_rate
          )
    return obj

  def Samme_R(self,
        
        learning_rate=1
           ):
    r"""Class information:
    ==================
    
    SAMME.R real boosting algorithm implementation
    
    Implements the SAMME.R real boosting algorithm proposed by J. Zhu,
    H. Zou, S. Rosset and T. Hastie ("Multi-class AdaBoost", 2009).
    
    One can set the learning rate which specifies the contribution of
    each classifier.
    
    Output when using BoostingLeafManager is
    :math:`log(p_k^m(x))-1/K*sum_k(log(p_k^m(x)))`.
    
    with :math:`x` the sample to classify, :math:`K` the number of classes,
    :math:`k` the classIndex, :math:`m` the estimatorIndex and :math:`p` the
    estimator probability.
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - int; int; uint; std::vector<float>; std::vector<float>
    - float; float; uint; std::vector<float>; std::vector<float>
    - double; double; uint; std::vector<float>; std::vector<float>
    - uint8_t; uint8_t; uint; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; uint; std::vector<float>; std::vector<float>
    - uint8_t; int16_t; int16_t; std::vector<float>; std::vector<float>
    
    Serialization generation: 101
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    r"""
    attrname = 'Samme_R_%s_%s_%s_%s_%s' % (self._inp_str, self._feat_str, self._ann_str, self._tres, self._fres)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        learning_rate
          )
    return obj

  def ShannonEntropy(self,
        
           ):
    r"""Class information:
    ==================
    
    Computes the classical Shannon-Entropy.
    
    Works correctly up to a total sum of elements of
    numeric_limits<input_dtype>::max().
    
    For classes :math:`C={c_1, \ldots, c_n}`, the Shannon entropy is defined as
    
    .. math::
      -\sum_{c\in C}p_z\cdot \log_2 p_z.
    
    
    The differential Shannon entropy for a normal distribution with covariance
    matrix :math:`\Sigma` in :math:`n` dimensions is defined as
    
    .. math::
      \frac{1}{2}\log\left((2\pi e)^n\left|\Sigma\right|\right).
    
    
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - float
    - uint
    
    Soil type always:
    
    - float
    
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    r"""
    attrname = 'ShannonEntropy_%s' % ('f')
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
          )
    return obj

  def StandardFeatureSelectionProvider(self,
        
        n_selections_per_node,
        selection_dimension,
        how_many_available,
        max_to_use=0,
        random_seed=1
           ):
    r"""Class information:
    ==================
    
    This selection provider generates random selection combinations.
    
    It may be seeded for reproducible results. It can be configured to only
    use a part of the available data dimensions. It only uses then the first
    that are registered as used.
    
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    Constructor:
    ============
    
    Standard constructor.
    
    Additional constraints on the methods arguments apply to guarantee good
    random selection speed:
    
    .. math::
      {{how\_many\_available}\choose{selection\_dimension}}\ge
    n\_selections\_per\_node\cdot 2,
    
    
    .. math::
      {{max\_to\_use}\choose{selection\_dimension}}\ge
    n\_selections\_per\_node\cdot 2.
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    n_selections_per_node : size_t>0
      How many selection proposals are created for each node.
    
    selection_dimension : size_t>0
      How many data dimensions are selected per
      proposal. Must be > 0 and < how_many_available.
    
    how_many_available : size_t>0
      How many data dimensions are available.
    
    max_to_use : size_t
      How many data dimensions may be used. If set to zero, use how_many_available.
      Default: 0.
    
    random_seed : uint>0
      A random seed for the random number generator. Must
      be greater than 0. Default: 1.
    r"""
    attrname = 'StandardFeatureSelectionProvider' % ()
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        n_selections_per_node,
        selection_dimension,
        how_many_available,
        max_to_use,
        random_seed
          )
    return obj

  def SubsamplingDataProvider(self,
        
        max_samples_per_node,
        sample_manager,
        random_seed=1
           ):
    r"""Class information:
    ==================
    
    Uses at maximum a certain amount of samples for node optimization.
    
    Tracks the loaded samples during training and adds new samples if possible.
    For leafs, all samples are loaded, even if its more than the maximum
    number of samples for split optimization.
    
    
    Can only be used for DFS (!!) for efficiency reasons.
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - uint8_t; int16_t
    - uint8_t; uint
    
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    max_samples_per_node : size_t>0
      The maximum number of samples to use for split optimization.
    
    sample_manager : shared(ISampleManager)
      The ISampleManager to use to handle the samples.
    
    random_seed : uint>0
      The seed for the RNG.
    r"""
    attrname = 'SubsamplingDataProvider_%s_%s' % (self._inp_str, self._ann_str)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        max_samples_per_node,
        sample_manager,
        random_seed
          )
    return obj

  def ThresholdDecider(self,
        
        selection_provider,
        feature_calculator,
        threshold_optimizer,
        n_valid_features_to_use=0,
        num_threads=1,
        use_hough_heuristic=0,
        hough_heuristic_ratio=0.05,
        hough_heuristic_maxd=0,
        allow_early_stopping=0
           ):
    r"""Class information:
    ==================
    
    A classifier manager for weak classifiers with a filter function,
    a feature calculation function and a thresholding.
    
    The classifier design is heavily inspired by "Decision Forests for
    Classification, Regression, Density Estimation, Manifold Learning and
    Semi-Supervised Learning" (Criminisi, Shotton and Konukoglu, 2011).
    With their definition, node classifier parameters :math:`\theta` can
    be split into three parts:
    
    - :math:`\phi`: a filter function that selects relevant features,
    - :math:`\psi`: parameters of a function that combines the feature values
    to a single scalar,
    - :math:`\tau`: thresholding parameters for the calculated scalar.
    
    With this model, a decision can be made at each node based on whether the
    calculated scalar lies withing the thresholding bounds.
    
    
    -----

    Available in:
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - int; int; uint
    - uint8_t; uint8_t; uint
    - uint8_t; int16_t; uint
    - float; float; uint
    - double; double; uint
    - uint8_t; int16_t; int16_t
    - float; float; float
    - double; double; double
    
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    selection_provider : shared(IFeatureSelectionProvider)
      It suggests tuples
      for the optimization of :math:`\phi`. It must be compatible
      to the feature calculator.
    
    feature_calculator : shared(ISurfaceCalculator)
      The feature calculation function. Its
      parameters are :math:`\psi`, and it combines the data
      dimensions to a single scalar feature.
    
    threshold_optimizer : shared(IThresholdOptimizer)
      Optimizes :math:`\tau`.
    
    n_valid_features_to_use : size_t
      The threshold optimizer may hint that
      a selected feature may be completely inappropriate for the
      currently searched split. If the feature selection provider
      does provide  sufficiently many features, the classifier may
      use the next one and "not count" the inappropriate one.
      This is the maximum number of "valid" features that are
      used per split. If 0, ignore the flag returned by the
      optimizer and always use all suggested feature combinations
      provided by the feature selection provider. Default: 0.
    
    num_threads : size_t>0
      The number of threads to use for threshold optimization.
      Independent of the number of threads, the result is
      guaranteed to be the same. Default: 1.
    
    use_hough_heuristic : bool
      Whether or not to use a heuristic for hough
      forests introduced by Juergen Gall
      (http://www.vision.ee.ethz.ch/~gallju/projects/houghforest/houghforest.html)
      Can be used only with an AlternatingThresholdOptimizer.
      If used, the AlternatingThresholdOptimizer will guaranteed
      use opt2 if the ratio of negative samples is < hough_heuristic_ratio or
      depth >= hough_heuristic_maxd. opt2 must be a
      VarianceClassificationThresholdOptimizer (check this
      manually!). Default: false.
    
    hough_heuristic_ratio : float>=0.f
      Default: 0.05f.
    
    hough_heuristic_maxd : uint
      Default: 0.
    
    allow_early_stopping : bool
      Allows the threshold optimizer to stop training if, e.g., all samples
      are of the same class in a classification setting. This is currently
      only supported by the classification threshold optimizers for 1D
      class annotations. Default: false.
    r"""
    attrname = 'ThresholdDecider_%s_%s_%s' % (self._inp_str, self._feat_str, self._ann_str)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        selection_provider,
        feature_calculator,
        threshold_optimizer,
        n_valid_features_to_use,
        num_threads,
        use_hough_heuristic,
        hough_heuristic_ratio,
        hough_heuristic_maxd,
        allow_early_stopping
          )
    return obj

  def TsallisEntropy(self,
        
        q
           ):
    r"""Class information:
    ==================
    
    Computes the Tsallis entropy.
    
    Works correctly up to a total sum of elements of
    numeric_limits<input_dtype>::max().
    
    This is the Tsallis entropy, as introduced by Constantino Tsallis
    (see http://en.wikipedia.org/wiki/Tsallis_entropy).
    
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - float
    - uint
    
    Soil type always:
    
    - float
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    q : float>0.f
      The entropy parameter.
    r"""
    attrname = 'TsallisEntropy_%s' % ('f')
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        q
          )
    return obj

  def TwoSideClassificationThresholdOptimizer(self,
        
        use_fast_search_approximation,
        n_classes,
        gain_calculator,
        gain_threshold=1E-7,
        annotation_step=1
           ):
    r"""Class information:
    ==================
    
    Optimizes two sided classifcation thresholds very efficiently.
    
    Supports only classification annotations (unsigned int) with annotation
    values in {0, ..., n_classes - 1}.
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - int; int; uint
    - int; float; uint
    - float; int; uint
    - uint8_t; int; uint
    - uint8_t; uint8_t; uint
    - uint8_t; float; uint
    - uint8_t; int16_t; uint
    - float; float; uint
    - double; double; uint
    - uint8_t; int16_t; int16_t
    
    
    -----

    Constructor:
    ============
    
    Standard constructor.
    
    use_fast_search_approximation is an interesting option to speed up the
    optimization process. In any case, the elements are sorted in
    feature order. If use_fast_search_approximation is set to true, the
    gain is only calculated at positions, where the currently considered
    element is from a different class than the last one AND if the
    feature value changed. The approximation does a greedy search,
    whereas all threshold combinations are evaluated for exact search
    (requires :math:`O(n^2)` time, where :math:`n` is n_examples)!
    
    This is a true approximation (i.e. the optimal gain can be at a
    position where the current element is from the same class than the
    last), but this hardly ever occurs for the usual gain calculation
    functions.
    
    A necessary, but not sufficient criterion for the approximation to
    be equal to the optimal value is the following:
    Assuming the (weighted) histogram values at position :math:`k` are
    :math:`k_{li}` for the left hand-side histogram and :math:`k_{ri}` for the
    right hand-side histogram, :math:`i\in[0,n\_classes-1]`. Then the gain
    function :math:`g(.)` must have the property
    
    .. math::
      \forall j\forall k_{li},k_{ri}: g(\{k_{li}\},\{k_{ri}\})<
    g(\{k_{li}\}_{i\backslash j}\cup\{k_{lj}+1\},
    \{k_{ri}\}_{i\backslash j}\cup\{k_{rj}-1\}) \vee
    g(\{k_{li}\}_{i\backslash j}\cup\{k_{lj}-1\},
    \{k_{ri}\}_{i\backslash j}\cup\{k_{rj}+1\})
    .
    
    This does not hold in general, but for the standard information gain
    based measures, cases where it doesn't hold occur very rarely and even
    if so, the found positions aren't a lot worse than the theoretical
    optimum.
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    use_fast_search_approximation : bool
      Behaviour as described above.
    
    n_classes : size_t>1
      The number of classes in the data.
    
    ent_calc : shared(IGainCalculator<float>)
      The gain calculator to use to estimate the gain.
    
    gain_threshold : float>=0.f
      The minimum gain to accept a split as valid. Default: 1E-7f.
    
    annotation_step : size_t>0
      The step size in memory for the annotations.
    r"""
    attrname = 'TwoSideClassificationThresholdOptimizer_%s_%s_%s' % (self._inp_str, self._feat_str, self._ann_str)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        use_fast_search_approximation,
        n_classes,
        gain_calculator,
        gain_threshold,
        annotation_step
          )
    return obj

  def UnchangedDataProvider(self,
        
        data,
        annotations
           ):
    r"""Class information:
    ==================
    
    Uses the provided data unchanged throughout the training.
    
    It builds its sample database from two pointer on memory arrays with
    data and annotations. Both must be provided in contiguous layout. The
    data (but not the annotations!) can be provided row- or column-wise.
    Column-wise layout is to be preferred, since it has more locality for
    most optimization processes.
    
    The annotations MUST always be provided in row major order, independent
    of the provided value for column_wise.
    
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - float; uint
    - int; uint
    - uint8_t; uint
    - uint8_t; int16_t
    - double; uint
    - double; double
    - float; float
    
    
    -----

    Constructor:
    ============
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - float; uint
    - uint8_t; uint
    - uint8_t; int16_t
    - double; uint
    - double; double
    - float; float
    
    
    -----

    
    Parameters
    ==========
    
    data_array : Array<input_dtype>, 2D, row-major contiguous.
      The data to use, with one data sample per row.
    
    annotation_array : Array<annotation_dtype>, 2D, row-major contiguous.
      The annotations to use, with one annotation per row.
    r"""
    attrname = 'UnchangedDataProvider_%s_%s' % (self._inp_str, self._ann_str)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        data,
        annotations
          )
    return obj

  def UnchangedFDataProvider(self,
        
        data_array,
        annotation_array
           ):
    r"""Class information:
    ==================
    
    Uses unchanged data providers for each tree.
    
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - float; uint
    - int; uint
    - uint8_t; uint
    - uint8_t; int16_t
    - double; uint
    - double; double
    - float; float
    
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - float; uint
    - uint8_t; uint
    - uint8_t; int16_t
    - double; uint
    - double; double
    - float; float
    
    
    -----

    
    Parameters
    ==========
    
    data_array : Array<input_dtype>, 2D, row-major contiguous.
      The data to use, with one data sample per row.
    
    annotation_array : Array<annotation_dtype>, 2D, row-major contiguous.
      The annotations to use, with one annotation per row.
    r"""
    attrname = 'UnchangedFDataProvider_%s_%s' % (self._inp_str, self._ann_str)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        data_array,
        annotation_array
          )
    return obj

  def VarianceClassificationThresholdOptimizer(self,
        
        n_thresholds,
        n_classes=2,
        offset_dim=2,
        gain_threshold=0,
        random_seed=1
           ):
    r"""Class information:
    ==================
    
    Optimizes a threshold by selecting the best some random values with respect to the variance of example offsets.
    
    The annotations are assumed to be a class label followed by its offset
    values. Since all these values must be of the same datatype, the only supported type
    is (signed) int in this case (to allow for negative offsets). The class labels
    must still be in [0; n_classes - 1].
    
    This threshold optimizer draws n_thresholds random values between
    the minimum and maximum observed feature value and returns the best
    one.
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - int; int; uint
    - int; float; uint
    - float; int; uint
    - uint8_t; int; uint
    - uint8_t; uint8_t; uint
    - uint8_t; float; uint
    - uint8_t; int16_t; uint
    - float; float; uint
    - double; double; uint
    - uint8_t; int16_t; int16_t
    
    
    -----

    Constructor:
    ============
    
    Standard constructor.
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    n_thresholds : size_t>0
      The number of thresholds to evaluate per split.
    
    n_classes : size_t>1
      The number of classes in the data. Currently only 2 are supported! Default: 2.
    
    offset_dim : size_t>0
      The dimensionality of the offset annotation (usually 2). Default: 2.
    
    gain_threshold : float
      The minimum gain to accept a split as valid. Default: 0.f.
    
    random_seed : unsigned int>0
      The seed for the RNG. Must be greater 0. Default: 1.
    r"""
    attrname = 'VarianceClassificationThresholdOptimizer_%s_%s_%s' % (self._inp_str, self._feat_str, self._ann_str)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        n_thresholds,
        n_classes,
        offset_dim,
        gain_threshold,
        random_seed
          )
    return obj

  def VarianceClassificationThresholdOptimizerWEntropy(self,
        
        n_thresholds,
        n_classes,
        offset_dim,
        ent_calc,
        gain_threshold=1,
        random_seed=1
           ):
    r"""Class information:
    ==================
    
    Optimizes a threshold by selecting the best some random values with respect to the variance of example offsets.
    
    The annotations are assumed to be a class label followed by its offset
    values. Since all these values must be of the same datatype, the only supported type
    is (signed) int in this case (to allow for negative offsets). The class labels
    must still be in [0; n_classes - 1].
    
    This threshold optimizer draws n_thresholds random values between
    the minimum and maximum observed feature value and returns the best
    one.
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - int; int; uint
    - int; float; uint
    - float; int; uint
    - uint8_t; int; uint
    - uint8_t; uint8_t; uint
    - uint8_t; float; uint
    - uint8_t; int16_t; uint
    - float; float; uint
    - double; double; uint
    - uint8_t; int16_t; int16_t
    
    
    -----

    Constructor:
    ============
    
    Constructor with optional entropy function specification.
    
    Parameters
    ==========
    
    n_thresholds : size_t
      The number of thresholds to evaluate per split.
    
    n_classes : size_t
      The number of classes in the data. Currently only 2 are supported! Default: 2.
    
    offset_dim : size_t
      The dimensionality of the offset annotation (usually 2). Default: 2.
    
    ent_calc : shared(IEntropyFunction<float>) or nullptr
      If not nullptr, a normal distribution of offsets is assumed and the
      entropy is measured using the specified differential entropy.
      Default: nullptr.
    
    gain_threshold : float
      The minimum gain to accept a split as valid. Default: 0.f.
    
    random_seed : unsigned int>0
      The seed for the RNG. Must be greater 0. Default: 1.
    
    -----

    Available in:
    
    - C++
    - Python
    
    Exported name: VarianceClassificationThresholdOptimizerWEntropy
    
    -----

    r"""
    attrname = 'VarianceClassificationThresholdOptimizer_%s_%s_%s' % (self._inp_str, self._feat_str, self._ann_str)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        n_thresholds,
        n_classes,
        offset_dim,
        ent_calc,
        gain_threshold,
        random_seed
          )
    return obj

  def VolumeFeatureSelectionProvider(self,
        
        selection_dimension,
        size_x,
        size_y,
        size_z,
        how_many_per_node,
        random_seed=1
           ):
    r"""Class information:
    ==================
    
    This selection provider generates random selection combinations
    from a 3D feature volume.
    
    It may be seeded for reproducible results.
    
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    Constructor:
    ============
    
    Standard constructor.
    
    Additional constraints on the methods arguments apply to guarantee good
    random selection speed:
    
    .. math::
      {{how\_many\_available}\choose{selection\_dimension}}\ge
    n\_selections\_per\_node\cdot 2,
    
    
    .. math::
      {{max\_to\_use}\choose{selection\_dimension}}\ge
    n\_selections\_per\_node\cdot 2.
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    selection_dimension : size_t>0
      How many data dimensions are selected per
      proposal. Must be > 0 and <= size_x*size_y*size_z.
    
    size_x : size_t>0
      Horizontal patch size.
    
    size_y : size_t>0
      Vertical patch size.
    
    size_z : size_t>0
      Patch depth.
    
    how_many_per_node : size_t>0
      How many selection proposals are created for each node.
    
    random_seed : A random seed for the random number generator. Must
      be greater than 0.
    r"""
    attrname = 'VolumeFeatureSelectionProvider' % ()
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        selection_dimension,
        size_x,
        size_y,
        size_z,
        how_many_per_node,
        random_seed
          )
    return obj

  def BoostingLeafManager(self,
        
        n_classes
           ):
    r"""Class information:
    ==================
    
    Allows the boosting strategies to set their own tree functions
    to influence the combined result.
    
    Using thes LeafManager may lead to better classifcation results.
    
    Note that the output does not represent probabilites and may vary when
    using different IBoostingStrategies
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - int; uint
    - float; uint
    - double; uint
    - uint8_t; uint
    - uint8_t; int16_t
    
    Serialization generation: 101
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    n_classes : uint>1
      The number of classes.
    r"""
    attrname = 'BoostingLeafManager_%s_%s' % (self._inp_str, self._ann_str)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        n_classes
          )
    return obj

  def NoCopyPatchSampleManager(self,
        
        images,
        patch_descs,
        n_positives,
        patch_size_z,
        patch_size_y,
        patch_size_x,
        patches_luc=0
           ):
    r"""Class information:
    ==================
    
    A sample manager for Hough forests that limits the number of
    patches for one node, but does not copy anything but uses direct access
    tricks.
    
    
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - uint8_t; int16_t
    - uint8_t; uint
    
    
    -----

    Constructor:
    ============
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    images : vector(Array<input_dtype>, 3D, row-major contiguous)
      Images of shape (n_features, height, width).
    
    patch_descs : Array<annotation_dtype, 3D, row-major contiguous)
      2D array in row major format with
      the patch descriptions. A patch description consists of 5 values:
      image id, position x, y, offset x, y (from the object to detect,
      so that position x + offset x = object x).
    
    n_positives : size_t>0
      The first n_positive examples are interpreted as
      positives, the rest as negatives (they get an according annotation).
    
    patch_size_z : size_t>0
      Patch depth.
    
    patch_size_y : size_t>0
      Patch height.
    
    patch_size_x : size_t>0
      Patch width.
    
    patches_luc : bool
      If true, it is assumed that the patch descriptions
      contain the _L_eft _U_pper _C_orners of the patches. Otherwise, it
      it assumed they contain the center points. In the luc case, the patch
      goes from (including) position{x,y} to (excluding)
      position{x,y}+{width, height}. In the center case, the patch goes
      from (including) position{x,y}-{width//2, height//2} up to (excluding)
      position{x,y}-{(width//2-width), (height//2-height)}. Default: false.
    r"""
    attrname = 'NoCopyPatchSampleManager_%s_%s' % (self._inp_str, self._ann_str)
    cons_method = None
    for part_mod in _pyfertilized:
        if hasattr(part_mod, attrname):
            cons_method = part_mod.__dict__[attrname]
            break
    if cons_method is None:
      raise Exception("This object is not supported by the current Soil (pyfertilized.%s)!" % (attrname))
    obj = cons_method(
        images,
        patch_descs,
        n_positives,
        patch_size_z,
        patch_size_y,
        patch_size_x,
        patches_luc
          )
    return obj

  def StandardClassificationForest(self,
      
        n_classes,
        n_features,
        max_depth=0,
        test_n_features_per_node=0,
        n_thresholds_per_feature=0,
        n_trees=10,
        min_samples_per_leaf=1,
        min_samples_per_split=2,
        min_gain_threshold=1E-7,
        allow_redraw=1,
        random_seed=1,
        entropy_name="induced",
        entropy_p1=2,
        threshold_optimization_threads=1
          ):
    r"""Constructs a default decision forest for classification.
    
    The forest uses axis-aligned threshold deciders. The default values for
    each of the parameters lead to the parameter choice by various
    heuristics. The results should be similar to those of the
    ClassificationForest object of scikit-learn.
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - int
    - float
    - double
    - uint8_t
    
    Exported name: StandardClassificationForest
    
    -----

    
    Parameters
    ==========
    
    n_classes : uint>1
      The number of classes. All annotation labels must be in
      [0, ..., n_classes[.
    
    n_features : size_t>0
      The number of features available.
    
    max_depth : uint>=0
      The maximum tree depth. If 0, it is set to UINT_MAX to allow for
      maximally large trees. Default: 0.
    
    test_n_features_per_node : size_t>=0
      The number of features to evaluate as split criteria at each tree
      node. If 0, it is set to sqrt(n_features). Default: 0.
    
    n_thresholds_per_features : size_t>=0
      The number of thresholds to evaluate per feature. If set to zero,
      search for the perfect split. Default: 0.
    
    n_trees : uint>1
      The number of trees to use. Default: 10.
    
    min_samples_per_leaf : uint>0
      The minimum number of samples at a leaf node.  Default: 1.
    
    min_samples_per_split : uint>2*min_samples_per_leaf
      The minimum number of samples to continue splitting. Default: 2.
    
    min_gain_threshold
      The minimum gain that must be reached to continue splitting. Default: 1E-7.
    
    allow_redraw : bool
      If set to true, allows to try a new feature when optimizing for a
      split, when for a feature no split could be found that satisfied
      the minimum number of samples per leaf for each subgroup. This may be
      done until all features have been checked. Default: true.
    
    random_seed : uint>=1
      The random seed to initialize the RNG. Default: 1.
    
    entropy_name : string in ["induced", "classification_error", "renyi", "tsallis", "shannon"]
      The entropy type to use. For the specification of induced entropy,
      see the "Publications" page. Default: 'induced'.
    
    entropy_p1 : float
      The entropy parameter. Might be unused (e.g. for the Shannon entropy).
      Default: 2.
    
    threshold_optimization_threads : uint>0
      The number of threads to use for threshold optimization. Default: 1.
    r"""
    attrname = 'construct_classifier_forest_%s' % (self._inp_str)
    if not hasattr(_pyfertilized_mf, attrname):
      raise Exception("This function is not supported by the current Soil (pyfertilized_mf.%s)!" % (attrname))
    exec_obj = _pyfertilized_mf.__dict__[attrname]
    return exec_obj(
        n_classes,
        n_features,
        max_depth,
        test_n_features_per_node,
        n_thresholds_per_feature,
        n_trees,
        min_samples_per_leaf,
        min_samples_per_split,
        min_gain_threshold,
        allow_redraw,
        random_seed,
        entropy_name,
        entropy_p1,
        threshold_optimization_threads
          )

  def StandardClassificationTree(self,
      
        n_classes,
        n_features,
        max_depth=0,
        test_n_features_per_node=0,
        n_thresholds_per_feature=0,
        min_samples_per_leaf=1,
        min_samples_per_split=2,
        min_gain_threshold=1E-7,
        allow_redraw=1,
        random_seed=1,
        entropy_name="induced",
        entropy_p1=2,
        threshold_optimization_threads=1
          ):
    r"""Constructs a default decision tree for classification.
    
    It uses an axis aligned decider.
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - int
    - float
    - double
    - uint8_t
    
    Exported name: StandardClassificationTree
    
    -----

    
    Parameters
    ==========
    
    n_classes : uint>1
      The number of classes. All annotation labels must be in
      [0, ..., n_classes[.
    
    n_features : size_t>0
      The number of features available.
    
    max_depth : uint>=0
      The maximum tree depth. If 0, it is set to UINT_MAX to allow for
      maximally large trees. Default: 0.
    
    test_n_features_per_node : size_t>=0
      The number of features to evaluate as split criteria at each tree
      node. If 0, it is set to sqrt(n_features). Default: 0.
    
    n_thresholds_per_feature : size_t>=0
      The number of thresholds to evaluate per feature. If set to zero,
      search for the perfect split. Default: 0.
    
    min_samples_per_leaf : uint>0
      The minimum number of samples at a leaf node. Default: 1.
    
    min_samples_per_split : uint>2*min_samples_per_leaf
      The minimum number of samples to continue splitting. Default: 2.
    
    min_gain_threshold
      The minimum gain that must be reached to continue splitting. Default: 1E-7.
    
    allow_redraw : bool
      If set to true, allows to try a new feature when optimizing for a
      split, when for a feature no split could be found that satisfied
      the minimum number of samples per leaf for each subgroup. This may be
      done until all features have been checked. Default: true.
    
    random_seed : uint>=1
      The random seed to initialize the RNG. Default: 1.
    
    entropy_name : string in ["induced", "classification_error", "renyi", "tsallis", "shannon"]
      The entropy type to use. For the specification of induced entropy,
      see the "Publications" page. Default: 'induced'.
    
    entropy_p1 : float
      The entropy parameter. Might be unused (e.g. for the Shannon entropy).
      Default: 2.
    
    threshold_optimization_threads : uint>0
      The number of threads to use for threshold optimization. Default: 1.
    r"""
    attrname = 'construct_classifier_tree_%s' % (self._inp_str)
    if not hasattr(_pyfertilized_mf, attrname):
      raise Exception("This function is not supported by the current Soil (pyfertilized_mf.%s)!" % (attrname))
    exec_obj = _pyfertilized_mf.__dict__[attrname]
    return exec_obj(
        n_classes,
        n_features,
        max_depth,
        test_n_features_per_node,
        n_thresholds_per_feature,
        min_samples_per_leaf,
        min_samples_per_split,
        min_gain_threshold,
        allow_redraw,
        random_seed,
        entropy_name,
        entropy_p1,
        threshold_optimization_threads
          )

  def FastRegressionForest(self,
      
        n_features,
        max_depth=0,
        test_n_features_per_node=0,
        n_thresholds_per_feature=10,
        n_trees=10,
        min_samples_per_leaf=3,
        min_samples_per_split=6,
        min_gain_threshold=1E-7,
        allow_redraw=1,
        random_seed=1,
        entropy_name="shannon",
        entropy_p1=2,
        numerical_zero_threshold=-1,
        threshold_optimization_threads=1,
        summary_mode=0
          ):
    r"""Constructs a fast decision forest for regression.
    
    It uses an axis aligned decider and uses constant regression at split
    and linear regression at leaf nodes.
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - float
    - double
    
    Exported name: FastRegressionForest
    
    -----

    
    Parameters
    ==========
    
    n_features : size_t>0
      The number of features available.
    
    max_depth : uint>=0
      The maximum tree depth. If 0, it is set to UINT_MAX to allow for
      maximally large trees. Default: 0.
    
    test_n_features_per_node : size_t>=0
      The number of features to evaluate as split criteria at each tree
      node. If 0, it is set to sqrt(n_features). Default: 0.
    
    n_thresholds_per_feature : size_t>0
      The number of thresholds to evaluate per feature. Default: 10.
    
    n_trees : size_t>1
      The number of trees. Default: 10.
    
    min_samples_per_leaf : uint>0
      The minimum number of samples at a leaf node.  Default: 3.
    
    min_samples_per_split : uint>2*min_samples_per_leaf
      The minimum number of samples to continue splitting. Default: 6.
    
    min_gain_threshold
      The minimum gain that must be reached to continue splitting. Default: 1E-7.
    
    allow_redraw : bool
      If set to true, allows to try a new feature when optimizing for a
      split, when for a feature no split could be found that satisfied
      the minimum number of samples per leaf for each subgroup. This may be
      done until all features have been checked. Default: true.
    
    random_seed : uint>=1
      The random seed to initialize the RNG. Default: 1.
    
    entropy_name : string in ["induced", "classification_error", "renyi", "tsallis", "shannon"]
      The entropy type to use. For the specification of induced entropy,
      see the "Publications" page. Default: 'shannon'.
    
    entropy_p1 : float
      The entropy parameter. Might be unused (e.g. for the Shannon entropy).
      Default: 1E-7.
    
    numerical_zero_threshold : float>=0.f || -1.f
      The threshold below of which all values are treated as zeros.
      If set to -1.f, use the value suggested by Eigen. Default: -1.f.
    
    threshold_optimization_threads : uint>0
      The number of threads to use for threshold optimization. Default: 1.
    
    summary_mode : uint<3
      Determines the meaning of the values in the prediction matrix of
      the forest (the output of the convenience `predict` method of a forest).
      Case 0: Each row contains the prediction for each regressor (the first
      half of its entries) and the expected variances for each
      regressor (second half of its entries). To estimate the joint
      variance, a gaussian is fitted over the multimodal distribution
      defined by all trees.
      Case 1: Each row contains the prediction for each regressor (the first
      half of its entries) and the mean of the expected variances of
      each tree. This has no direct semantic meaning, but can give
      better results in active learning applications.
      Case 2: Each row contains the prediction for each regressor and
      the variance estimate for each regressor for each tree, e.g.,
      (r11, r12, v11, v12, r21, r22, v21, v22, ...), with `r` and `v`
      denoting regressor prediction and variance respectively, the
      first index the tree and the second index the regressor index.
      Default: 0.
    r"""
    attrname = 'construct_fast_regression_forest_%s' % (self._inp_str)
    if not hasattr(_pyfertilized_mf, attrname):
      raise Exception("This function is not supported by the current Soil (pyfertilized_mf.%s)!" % (attrname))
    exec_obj = _pyfertilized_mf.__dict__[attrname]
    return exec_obj(
        n_features,
        max_depth,
        test_n_features_per_node,
        n_thresholds_per_feature,
        n_trees,
        min_samples_per_leaf,
        min_samples_per_split,
        min_gain_threshold,
        allow_redraw,
        random_seed,
        entropy_name,
        entropy_p1,
        numerical_zero_threshold,
        threshold_optimization_threads,
        summary_mode
          )

  def FastRegressionTree(self,
      
        n_features,
        max_depth=0,
        test_n_features_per_node=0,
        n_thresholds_per_feature=10,
        min_samples_per_leaf=3,
        min_samples_per_split=6,
        min_gain_threshold=1E-7,
        allow_redraw=1,
        random_seed=1,
        entropy_name="shannon",
        entropy_p1=2,
        numerical_zero_threshold=-1,
        threshold_optimization_threads=1,
        summary_mode=0
          ):
    r"""Constructs a fast decision tree for regression.
    
    It uses an axis aligned decider and uses constant regression at split
    and linear regression at leaf nodes.
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - float
    - double
    
    Exported name: FastRegressionTree
    
    -----

    
    Parameters
    ==========
    
    n_features : size_t>0
      The number of features available.
    
    max_depth : uint>=0
      The maximum tree depth. If 0, it is set to UINT_MAX to allow for
      maximally large trees.
    
    test_n_features_per_node : size_t>=0
      The number of features to evaluate as split criteria at each tree
      node. If 0, it is set to sqrt(n_features). Default: 0.
    
    n_thresholds_per_feature : size_t>0
      The number of thresholds to evaluate per feature. Default: 10.
    
    min_samples_per_leaf : uint>0
      The minimum number of samples at a leaf node.  Default: 3.
    
    min_samples_per_split : uint>2*min_samples_per_leaf
      The minimum number of samples to continue splitting. Default: 6.
    
    min_gain_threshold
      The minimum gain that must be reached to continue splitting. Default: 1E-7.
    
    allow_redraw : bool
      If set to true, allows to try a new feature when optimizing for a
      split, when for a feature no split could be found that satisfied
      the minimum number of samples per leaf for each subgroup. This may be
      done until all features have been checked. Default: true.
    
    random_seed : uint>=1
      The random seed to initialize the RNG. Default: 1.
    
    entropy_name : string in ["induced", "classification_error", "renyi", "tsallis", "shannon"]
      The entropy type to use. For the specification of induced entropy,
      see the "Publications" page. Default: 'shannon'.
    
    entropy_p1 : float
      The entropy parameter. Might be unused (e.g. for the Shannon entropy).
      Default: 2.
    
    numerical_zero_threshold : float>=0.f || -1.f
      The threshold below of which all values are treated as zeros.
      If set to -1.f, use the value suggested by Eigen. Default: -1.f.
    
    threshold_optimization_threads : uint>0
      The number of threads to use for threshold optimization. Default: 1.
    
    summary_mode : uint<3
      Determines the meaning of the values in the prediction matrix of
      the forest (the output of the convenience `predict` method of a forest).
      Case 0: Each row contains the prediction for each regressor (the first
      half of its entries) and the expected variances for each
      regressor (second half of its entries). To estimate the joint
      variance, a gaussian is fitted over the multimodal distribution
      defined by all trees.
      Case 1: Each row contains the prediction for each regressor (the first
      half of its entries) and the mean of the expected variances of
      each tree. This has no direct semantic meaning, but can give
      better results in active learning applications.
      Case 2: Each row contains the prediction for each regressor and
      the variance estimate for each regressor for each tree, e.g.,
      (r11, r12, v11, v12, r21, r22, v21, v22, ...), with `r` and `v`
      denoting regressor prediction and variance respectively, the
      first index the tree and the second index the regressor index.
      Default: 0.
    r"""
    attrname = 'construct_fast_regression_tree_%s' % (self._inp_str)
    if not hasattr(_pyfertilized_mf, attrname):
      raise Exception("This function is not supported by the current Soil (pyfertilized_mf.%s)!" % (attrname))
    exec_obj = _pyfertilized_mf.__dict__[attrname]
    return exec_obj(
        n_features,
        max_depth,
        test_n_features_per_node,
        n_thresholds_per_feature,
        min_samples_per_leaf,
        min_samples_per_split,
        min_gain_threshold,
        allow_redraw,
        random_seed,
        entropy_name,
        entropy_p1,
        numerical_zero_threshold,
        threshold_optimization_threads,
        summary_mode
          )

  def StandardHoughTree(self,
      
        patch_dimensions,
        n_thresholds_per_split,
        n_splits_per_node,
        max_depth,
        min_sample_counts,
        random_seed,
        min_gain_thresholds,
        patch_annot_luc=0,
        allow_redraw=1,
        num_threads=1,
        entropy_names=_DEFAULT_ENTROPY_VEC_2,
        entropy_p1=_DEFAULT_ENTROPY_P1_2,
        use_hough_heuristic=1,
        hough_heuristic_ratio=0.05,
        hough_heuristic_maxd=0
          ):
    r"""Constructs a default Hough tree.
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - uint8_t; int16_t; int16_t
    
    Exported name: StandardHoughTree
    
    -----

    
    Parameters
    ==========
    
    patch_dimensions : vector<size_t>0>, three elements
      The patch size in x, y, z.
    
    n_thresholds_per_split : size_t>=0
      The number of thresholds to evaluate per feature.
    
    n_splits_per_node : size_t>0
      The number of features to evaluate as split criteria at each tree
      node.
    
    max_depth : uint>=0
      The maximum tree depth. If 0, it is set to UINT_MAX to allow for
      maximally large trees.
    
    min_sample_counts : vector<uint>0>, two elements.
      The min samples per leaf, and min samples per split. The second value
      must be >= 2 * the first value.
    
    random_seed : uint>=1
      The random seed to initialize the RNG.
    
    min_gain_thresholds : vector<float>=0.f>, two elements.
      The minimum gains for classification and regression.
    
    patch_annot_luc : bool
      Whether the patch annotations contain patch position for the patch
      left upper corner or patch center. Default: false.
    
    allow_redraw : bool
      If set to true, allows to try a new feature when optimizing for a
      split, when for a feature no split could be found that satisfied
      the minimum number of samples per leaf for each subgroup. This may be
      done until all features have been checked. Default: true.
    
    num_threads : uint>0
      The number of threads to use for optimizing the split nodes.
      Default: 1.
    
    entropy_names : vector<string in ["induced", "classification_error", "renyi", "tsallis", "shannon"]>, two elements.
      The entropy type to use for classification and regression.
      Default: ["shannon", "shannon"]
    
    entropy_p1 : vector<float>0.f>, two elements.
      The entropy parameters. Might be unused (e.g. for the Shannon entropy).
      Default: [2, 2]
    
    use_hough_heuristic : bool
      Whether or not to use a heuristic for hough
      forests introduced by Juergen Gall
      (http://www.vision.ee.ethz.ch/~gallju/projects/houghforest/houghforest.html)
      Can be used only with an AlternatingThresholdOptimizer.
      If used, the AlternatingThresholdOptimizer will guaranteed
      use opt2 if the ratio of negative samples is < hough_heuristic_ratio or
      depth >= hough_heuristic_maxd. opt2 must be a
      VarianceClassificationThresholdOptimizer (check this
      manually!). Default: true.
    
    hough_heuristic_ratio : float>=0.f
      Default: 0.05f.
    
    hough_heuristic_maxd : uint
      Default: 0.
    r"""
    attrname = 'construct_hough_tree_%s_%s_%s' % (self._inp_str, self._feat_str, self._ann_str)
    if not hasattr(_pyfertilized_mf, attrname):
      raise Exception("This function is not supported by the current Soil (pyfertilized_mf.%s)!" % (attrname))
    exec_obj = _pyfertilized_mf.__dict__[attrname]
    return exec_obj(
        patch_dimensions,
        n_thresholds_per_split,
        n_splits_per_node,
        max_depth,
        min_sample_counts,
        random_seed,
        min_gain_thresholds,
        patch_annot_luc,
        allow_redraw,
        num_threads,
        entropy_names,
        entropy_p1,
        use_hough_heuristic,
        hough_heuristic_ratio,
        hough_heuristic_maxd
          )

  def StandardRegressionForest(self,
      
        n_features,
        max_depth=0,
        test_n_features_per_node=0,
        n_thresholds_per_feature=10,
        n_trees=10,
        min_samples_per_leaf=3,
        min_samples_per_split=6,
        min_gain_threshold=1E-7,
        allow_redraw=1,
        random_seed=1,
        entropy_name="shannon",
        entropy_p1=2,
        numerical_zero_threshold=-1,
        threshold_optimization_threads=1,
        summary_mode=0
          ):
    r"""Constructs a default decision forest for regression.
    
    It uses an axis aligned decider and uses linear regression at split
    and leaf nodes.
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - float
    - double
    
    Exported name: StandardRegressionForest
    
    -----

    
    Parameters
    ==========
    
    n_features : size_t>0
      The number of features available.
    
    max_depth : uint>=0
      The maximum tree depth. If 0, it is set to UINT_MAX to allow for
      maximally large trees. Default: 0.
    
    test_n_features_per_node : size_t>=0
      The number of features to evaluate as split criteria at each tree
      node. If 0, it is set to sqrt(n_features). Default: 0.
    
    n_thresholds_per_feature : size_t>0
      The number of thresholds to evaluate per feature. Default: 10.
    
    n_trees : size_t>1
      The number of trees to use. Default: 10.
    
    min_samples_per_leaf : uint>0
      The minimum number of samples at a leaf node.  Default: 3.
    
    min_samples_per_split : uint>2*min_samples_per_leaf
      The minimum number of samples to continue splitting. Default: 6.
    
    min_gain_threshold
      The minimum gain that must be reached to continue splitting. Default: 1E-7.
    
    allow_redraw : bool
      If set to true, allows to try a new feature when optimizing for a
      split, when for a feature no split could be found that satisfied
      the minimum number of samples per leaf for each subgroup. This may be
      done until all features have been checked. Default: true.
    
    random_seed : uint>=1
      The random seed to initialize the RNG. Default: 1.
    
    entropy_name : string in ["induced", "classification_error", "renyi", "tsallis", "shannon"]
      The entropy type to use. For the specification of induced entropy,
      see the "Publications" page. Default: 'shannon'.
    
    entropy_p1 : float
      The entropy parameter. Might be unused (e.g. for the Shannon entropy).
      Default: 2.
    
    numerical_zero_threshold : float>=0.f || -1.f
      The threshold below of which all values are treated as zeros.
      If set to -1.f, use the value suggested by Eigen. Default: -1.f.
    
    threshold_optimization_threads : uint>0
      The number of threads to use for threshold optimization. Default: 1.
    
    summary_mode : uint<3
      Determines the meaning of the values in the prediction matrix of
      the forest (the output of the convenience `predict` method of a forest).
      Case 0: Each row contains the prediction for each regressor (the first
      half of its entries) and the expected variances for each
      regressor (second half of its entries). To estimate the joint
      variance, a gaussian is fitted over the multimodal distribution
      defined by all trees.
      Case 1: Each row contains the prediction for each regressor (the first
      half of its entries) and the mean of the expected variances of
      each tree. This has no direct semantic meaning, but can give
      better results in active learning applications.
      Case 2: Each row contains the prediction for each regressor and
      the variance estimate for each regressor for each tree, e.g.,
      (r11, r12, v11, v12, r21, r22, v21, v22, ...), with `r` and `v`
      denoting regressor prediction and variance respectively, the
      first index the tree and the second index the regressor index.
      Default: 0.
    r"""
    attrname = 'construct_regression_forest_%s' % (self._inp_str)
    if not hasattr(_pyfertilized_mf, attrname):
      raise Exception("This function is not supported by the current Soil (pyfertilized_mf.%s)!" % (attrname))
    exec_obj = _pyfertilized_mf.__dict__[attrname]
    return exec_obj(
        n_features,
        max_depth,
        test_n_features_per_node,
        n_thresholds_per_feature,
        n_trees,
        min_samples_per_leaf,
        min_samples_per_split,
        min_gain_threshold,
        allow_redraw,
        random_seed,
        entropy_name,
        entropy_p1,
        numerical_zero_threshold,
        threshold_optimization_threads,
        summary_mode
          )

  def StandardRegressionTree(self,
      
        n_features,
        max_depth=0,
        test_n_features_per_node=0,
        n_thresholds_per_feature=10,
        min_samples_per_leaf=3,
        min_samples_per_split=6,
        min_gain_threshold=1E-7,
        allow_redraw=1,
        random_seed=1,
        entropy_name="shannon",
        entropy_p1=2,
        numerical_zero_threshold=-1,
        threshold_optimization_threads=1,
        summary_mode=0
          ):
    r"""Constructs a default decision tree for regression.
    
    It uses an axis aligned decider and uses linear regression at split
    and leaf nodes.
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    Instantiations:
    
    - float
    - double
    
    Exported name: StandardRegressionTree
    
    -----

    
    Parameters
    ==========
    
    n_features : size_t>0
      The number of features available.
    
    max_depth : uint>=0
      The maximum tree depth. If 0, it is set to UINT_MAX to allow for
      maximally large trees. Default: 0.
    
    test_n_features_per_node : size_t>=0
      The number of features to evaluate as split criteria at each tree
      node. If 0, it is set to sqrt(n_features). Default: 0.
    
    n_thresholds_per_feature : size_t>0
      The number of thresholds to evaluate per feature. Default: 10.
    
    min_samples_per_leaf : uint>0
      The minimum number of samples at a leaf node. Default: 3.
    
    min_samples_per_split : uint>2*min_samples_per_leaf
      The minimum number of samples to continue splitting. Default: 6.
    
    min_gain_threshold
      The minimum gain that must be reached to continue splitting. Default: 1E-7.
    
    allow_redraw : bool
      If set to true, allows to try a new feature when optimizing for a
      split, when for a feature no split could be found that satisfied
      the minimum number of samples per leaf for each subgroup. This may be
      done until all features have been checked. Default: true.
    
    random_seed : uint>=1
      The random seed to initialize the RNG. Default: 1.
    
    entropy_name : string in ["induced", "classification_error", "renyi", "tsallis", "shannon"]
      The entropy type to use. For the specification of induced entropy,
      see the "Publications" page. Default: 'shannon'.
    
    entropy_p1 : float
      The entropy parameter. Might be unused (e.g. for the Shannon entropy).
      Default: 2.
    
    numerical_zero_threshold : float>=0.f || -1.f
      The threshold below of which all values are treated as zeros.
      If set to -1.f, use the value suggested by Eigen. Default: -1.f.
    
    threshold_optimization_threads : uint>0
      The number of threads to use for threshold optimization. Default: 1.
    
    summary_mode : uint<3
      Determines the meaning of the values in the prediction matrix of
      the forest (the output of the convenience `predict` method of a forest).
      Case 0: Each row contains the prediction for each regressor (the first
      half of its entries) and the expected variances for each
      regressor (second half of its entries). To estimate the joint
      variance, a gaussian is fitted over the multimodal distribution
      defined by all trees.
      Case 1: Each row contains the prediction for each regressor (the first
      half of its entries) and the mean of the expected variances of
      each tree. This has no direct semantic meaning, but can give
      better results in active learning applications.
      Case 2: Each row contains the prediction for each regressor and
      the variance estimate for each regressor for each tree, e.g.,
      (r11, r12, v11, v12, r21, r22, v21, v22, ...), with `r` and `v`
      denoting regressor prediction and variance respectively, the
      first index the tree and the second index the regressor index.
      Default: 0.
    r"""
    attrname = 'construct_regression_tree_%s' % (self._inp_str)
    if not hasattr(_pyfertilized_mf, attrname):
      raise Exception("This function is not supported by the current Soil (pyfertilized_mf.%s)!" % (attrname))
    exec_obj = _pyfertilized_mf.__dict__[attrname]
    return exec_obj(
        n_features,
        max_depth,
        test_n_features_per_node,
        n_thresholds_per_feature,
        min_samples_per_leaf,
        min_samples_per_split,
        min_gain_threshold,
        allow_redraw,
        random_seed,
        entropy_name,
        entropy_p1,
        numerical_zero_threshold,
        threshold_optimization_threads,
        summary_mode
          )

  def extract_hough_forest_features(self,
      
        image,
        full=0
          ):
    r"""Extract the Hough forest features. If `full` is set, uses the
    32 feature channels used by Juergen Gall in his original publications,
    else use 15 feature channels as used by Matthias Dantone.
    
    The image must be in OpenCV (BGR) channel format!
    
    -----

    Available in:
    
    - C++
    - Python
    - Matlab
    
    
    -----

    
    Parameters
    ==========
    
    image : Array<uint8_t>, row-major contiguous
      The source image.
    
    full : bool
      Whether to return the full feature set (32 layers) or not (15 layers).
      Default: false.
    r"""
    attrname = 'extract_hough_forest_features' % ()
    if not hasattr(_pyfertilized_mf, attrname):
      raise Exception("This function is not supported by the current Soil (pyfertilized_mf.%s)!" % (attrname))
    exec_obj = _pyfertilized_mf.__dict__[attrname]
    return exec_obj(
        image,
        full
          )

